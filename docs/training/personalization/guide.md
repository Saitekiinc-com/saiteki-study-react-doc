# 研修パーソナライズガイド

すべての研修生が同じバックグラウンドを持っているわけではありません。
特にAI時代の現在は、「AIでコードは書けるが原理を知らない」層や、「特定の領域は強いが他は未経験」な層など、多様なスキルセットが存在します。

本ガイドでは、**「開発ワークフロー全体（設計〜運用）をカバーできるエンジニア」** を目指すための、ペルソナ別学習戦略と、実務を通じた学習サイクルを定義します。

## 1. ターゲット別ペルソナ (Personas)

経験年数ではなく、**「ワークフローのどこにギャップ（弱点）があるか」** で分類します。

### Type A: The AI Soloist (AIネイティブ・個人開発レベル)
*   **現状**: CursorやChatGPTを使って、一人でWebアプリやLPを作ることができる。
*   **強み**: 実装スピードが速い。新しい技術への抵抗がない。
*   **ギャップ**: **「チーム開発」と「品質・保守性」**。
    *   コードがスパゲッティ化しており、他人が読めない。
    *   テストコードを書いたことがない。
    *   セキュリティやエラーハンドリングが甘い。
*   **重点学習領域**:
    *   **Lv.3 Quality**: テスト、可読性、保守性の高い設計。
    *   **Lv.4 Architecture**: チーム開発の標準化、CI/CD。
    *   **Lv.1 Workshop**: トラブルシューティング（AIが解決できない時の対応力）。

### Type B: The Frontend Specialist (React経験者)
*   **現状**: React/TypeScriptでのUI実装は得意。Figma通りに画面を作れる。
*   **強み**: UXへの感度が高い。コンポーネント設計ができる。
*   **ギャップ**: **「システム全体の視点」と「インフラ」**。
    *   APIの向こう側で何が起きているかイメージできない。
    *   AWSやデプロイ周りは「誰かがやってくれる」と思っている。
    *   パフォーマンス問題（N+1など）に気づけない。
*   **重点学習領域**:
    *   **Data Flow Guide**: システム全体のデータの流れ。
    *   **AWS / Infra**: コードが動く基盤の理解。
    *   **Lv.2 Application (Backend Part)**: APIとDBの基礎。

### Type C: The Backend/Infra Specialist (サーバーサイド強者)
*   **現状**: Go/Java/PythonでのAPI開発や、AWS構築は得意。
*   **強み**: 堅牢なロジック、セキュリティ、パフォーマンスへの理解。
*   **ギャップ**: **「ユーザー体験 (UX)」と「フロントエンドのメンタルモデル」**。
    *   Reactの「宣言的UI」や「再レンダリング」の挙動に戸惑う。
    *   UIの使い勝手やインタラクションへの関心が薄い。
*   **重点学習領域**:
    *   **Lv.1 Foundation (UI Section)**: Reactのメンタルモデル。
    *   **Lv.2 Application (Frontend Part)**: フォームや状態管理の実装。

---

## 2. 実務連動型学習サイクル (OJT Learning Cycle)

座学で全てを学んでから実務に入るのではなく、**「実務タスクをこなしながら学ぶ」** サイクルを回します。
AI時代において重要なのは、**「AIにコードを書かせ、人間がそれを審査（レビュー）する」** というプロセスです。

### サイクルの流れ

1.  **Trigger (課題着手)**: タスクが割り当てられる。
2.  **Execution (AI + Human)**: AIを活用して実装するが、**「なぜそう書くのか」を人間が理解・修正する**。
3.  **Review (知識の定着)**: レビューを通じて、知識の抜け漏れを確認する。
4.  **Reflection (言語化)**: 学んだことをドキュメントに残す。

### 領域別適用マトリクス

どの領域でも、**「AIのアウトプットを鵜呑みにせず、説明責任を持つ」** ことが学習の肝です。

| フェーズ | ⚛️ Frontend | 🔙 Backend | ☁️ Infra (AWS) | 🧪 QA |
| :--- | :--- | :--- | :--- | :--- |
| **1. Trigger**<br>(タスク例) | 「登録フォームの実装」 | 「ユーザーAPIの実装」 | 「S3バケットの追加」 | 「決済フローのテスト」 |
| **2. Execution**<br>(AI + Human) | AIがUIを生成。<br>**人間**: コンポーネント分割は適切か？再レンダリングの無駄はないか？ | AIがSQLを生成。<br>**人間**: N+1問題は起きないか？トランザクション範囲は正しいか？ | AIがTerraformを生成。<br>**人間**: IAM権限は最小か？パブリックアクセスは閉じたか？ | AIがテストを生成。<br>**人間**: エッジケースは網羅されているか？壊れやすいテストではないか？ |
| **3. Review**<br>(知識チェック) | 「なぜここで `useCallback` を使ったの？」<br>「エラー時のユーザーへの表示は？」 | 「SQLインジェクション対策は？」<br>「DB負荷が高まったらどうなる？」 | 「コスト最適化されている？」<br>「リージョン障害時の挙動は？」 | 「このテストで本当にリスクを防げる？」<br>「ユーザー視点で足りない観点は？」 |
| **4. Reflection**<br>(ドキュメント化) | Reactのレンダリングの仕組み | DBインデックスの貼り方 | IaCのベストプラクティス | テスト戦略の考え方 |

## 3. メンターへの推奨アクション

*   **「答え」ではなく「問い」を与える**:
    *   コードが動いていても、「なぜこのライブラリを選んだの？」「他の選択肢は検討した？」と問いかけることで、本人の理解度を深堀りしてください。
*   **AIの利用を禁止しない**:
    *   AIを使うこと自体は推奨しますが、**「説明できないコードのコミットは禁止」** というルールを徹底してください。
